{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abce2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests- download requests and beautifulsoup4 if not already installed\n",
    "# !pip install beautifulsoup4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdcea835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries Scraped:  4\n",
      "Number of Formal Terms Counted:  0\n",
      "Distribution of Formal Terms:  {'sodomy': 0, 'consent': 0, 'assault': 0}\n",
      "Number of Informal Terms Counted:  5\n",
      "Distribution of Informal Terms:  {'fuck': 0, 'ass': 5, 'bitch': 0}\n"
     ]
    }
   ],
   "source": [
    "# Establish a list of what words you are looking at for each category\n",
    "formal_terms = ['sodomy', 'consent', 'assault'] \n",
    "informal_terms = ['fuck', 'ass', 'bitch']\n",
    "formal_term_counts = {word: 0 for word in formal_terms}\n",
    "informal_term_counts = {word: 0 for word in informal_terms}\n",
    "# Create a list of links for journal entries you want to use ***MUST HAVE TRANSCRIPT TO WORK***\n",
    "entries = ['https://prisonwitness.org/apwa-essay/carceral-violence/',\n",
    "          'https://prisonwitness.org/apwa-essay/how-bizarre/',\n",
    "          'https://prisonwitness.org/apwa-essay/to-be-or-not-to-be-a-fundamentally-fair-republic/',\n",
    "          'https://prisonwitness.org/apwa-essay/solitary-confinement-my-typical-day-as-a-teenager-in-the-box-on-rikers-island/']\n",
    "# Looping thru entries\n",
    "num_entries = len(entries)\n",
    "for i in range(num_entries):\n",
    "    ############################\n",
    "    # Do not modify code within this hash block\n",
    "    r = requests.get(entries[i])\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    s = soup.find('div', class_='apwa-content')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    for i, p in enumerate(paragraphs):\n",
    "        if \"Transcript\" in p.get_text():\n",
    "            for next_p in paragraphs[i+1:]:\n",
    "                text = next_p.get_text(strip=True)\n",
    "                if text:\n",
    "                    transcript_text = text\n",
    "                    break\n",
    "            break\n",
    "    lower_text = transcript_text.lower()\n",
    "    #############################\n",
    "    # Counting each term. Here you can change your metrics if needed, I'm simply counting the words for this example.\n",
    "    for term in formal_terms:\n",
    "        formal_term_counts[term] = lower_text.count(term)\n",
    "    for term in informal_terms:\n",
    "        informal_term_counts[term] = lower_text.count(term)\n",
    "print(\"Number of Entries Scraped: \", num_entries)\n",
    "print(\"Number of Formal Terms Counted: \", sum(formal_term_counts.values()))\n",
    "print(\"Distribution of Formal Terms: \", formal_term_counts)\n",
    "print(\"Number of Informal Terms Counted: \", sum(informal_term_counts.values()))\n",
    "print(\"Distribution of Informal Terms: \", informal_term_counts)\n",
    "# Make sure to delete my comments lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b40f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
